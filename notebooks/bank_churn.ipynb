{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from scipy.stats.mstats import normaltest\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary_columns(\n",
    "    df: pd.DataFrame,\n",
    "    delete_columns: Dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Removes unnecessary columns from a DataFrame based on the\n",
    "    specified criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - delete_columns (Dict): A dictionary containing information\n",
    "      about columns to delete.\n",
    "        - 'selected_columns' (List[str]): List of column names to be deleted.\n",
    "        - 'threshold' (float): Threshold for missing data. Columns with\n",
    "          missing data exceeding this threshold will be deleted.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with unnecessary columns removed.\n",
    "    \"\"\"\n",
    "    df.drop(columns=delete_columns['selected_columns'], inplace=True)\n",
    "\n",
    "    missing_th = int((1 - delete_columns['threshold']) * len(df)) + 1\n",
    "\n",
    "    missing_data_cols = [\n",
    "        col for col in df.columns.tolist() if df[col].count() < missing_th\n",
    "    ]\n",
    "    logger = logging.getLogger(__name__)\n",
    "    if len(missing_data_cols) > 0:\n",
    "        df.drop(columns=missing_data_cols, inplace=True)\n",
    "        logger.info(\"Incomplete deleted columns: \", missing_data_cols)\n",
    "    else:\n",
    "        logger.info(\"There are not deleted columns\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_incomplete_rows(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    missing_data_cols = [\n",
    "        col for col in df.columns.tolist() if len(\n",
    "            df[pd.isnull(df[col])]\n",
    "        ) > 0\n",
    "    ]\n",
    "    for column in missing_data_cols:\n",
    "        null_values = df[pd.isnull(df[column])].index.tolist()\n",
    "        df.drop(null_values, axis=0, inplace=True)\n",
    "        # print(column, '\\t', len(null_values), '\\t', df[column].dtypes)\n",
    "    print(\"Incomplete deleted rows: \", missing_data_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def treat_skewed_columns(\n",
    "    df: pd.DataFrame,\n",
    "    skewed_columns: Dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Treats skewed numerical columns in a DataFrame using specified\n",
    "    transformation methods.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - skewed_columns (Dict): A dictionary containing information about columns\n",
    "      and transformation methods.\n",
    "        - 'exclude_columns' (List[str]): List of column names to be excluded\n",
    "          from skewness treatment.\n",
    "        - 'method' (str): Transformation method. Options: \"boxcox\" or \"log\".\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with treated skewed columns.\n",
    "    \"\"\"\n",
    "    mask_float = df.dtypes == np.float64\n",
    "    float_cols = df.columns[mask_float].tolist()\n",
    "    mask_int = df.dtypes == np.int64\n",
    "    int_cols = df.columns[mask_int].tolist()\n",
    "    numerical_cols = float_cols + int_cols\n",
    "\n",
    "    if len(numerical_cols) > 0 and len(skewed_columns['exclude_columns']) > 0:\n",
    "        for column in skewed_columns['exclude_columns']:\n",
    "            numerical_cols.remove(column)\n",
    "\n",
    "    transformed_columns = []\n",
    "    if skewed_columns['method'] == \"boxcox\":\n",
    "        boxcox_dict = {}\n",
    "        for col in numerical_cols:\n",
    "            print(col, min(df[col]))\n",
    "            df[col].fillna(0, inplace=True)\n",
    "            boxcox_current, lam = boxcox(df[col])\n",
    "            boxcox_dict.update({f\"{col}\": [boxcox_current, lam]})\n",
    "            df[col] = boxcox_current\n",
    "    elif skewed_columns['method'] == \"log\":\n",
    "        for col in numerical_cols:\n",
    "            p_value = normaltest(df[col].values)[1]\n",
    "            if p_value > 0.05:\n",
    "                # print(col, p_value)\n",
    "                if df[col].min() >= 0:\n",
    "                    df[col] = (df[col] + 1).transform(np.log)\n",
    "                else:\n",
    "                    df[col] = (df[col] - df[col].min() + 1).transform(np.log)\n",
    "                transformed_columns.append(col)\n",
    "\n",
    "    if len(transformed_columns) > 0:\n",
    "        print(\"Transformed columns: \", transformed_columns)\n",
    "    else:\n",
    "        print(\"There are not transformed columns\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def _get_anova_fvalue(\n",
    "    x: pd.DataFrame,\n",
    "    y: pd.Series\n",
    ") -> pd.DataFrame:\n",
    "    # Entre mayor sea el f1, quiere decir que la media entre las\n",
    "    # clases 0 y 1 de attrition, tiene una mayor variabilidad,\n",
    "    # lo que quiere decir que esa variable si importa en en an?lisis\n",
    "    f_scores = f_classif(x, y)[0]  # el [1] son los p-values.\n",
    "    df_fscores = pd.DataFrame({'features': x.columns, 'score': f_scores})\n",
    "    df_fscores = df_fscores.sort_values('score', ascending=False)\n",
    "\n",
    "    return df_fscores\n",
    "\n",
    "\n",
    "def _get_correlations(\n",
    "    data: pd.DataFrame,\n",
    "    threshold: float\n",
    ") -> pd.DataFrame:\n",
    "    xcorr = data.corr().abs()\n",
    "    xcorr = xcorr[xcorr > threshold].fillna(0)\n",
    "    column1 = []\n",
    "    column2 = []\n",
    "    for idx in list(xcorr.index):\n",
    "        for col in list(xcorr.columns):\n",
    "            # la matriz es diagonal\n",
    "            if idx == col:\n",
    "                break\n",
    "            if (xcorr.loc[idx, col] != 0):\n",
    "                column1 = column1 + [idx]\n",
    "                column2 = column2 + [col]\n",
    "    df_fcorr = pd.DataFrame({'column1': column1, 'column2': column2})\n",
    "    return df_fcorr\n",
    "\n",
    "\n",
    "def _remove_columns_by_correlation(\n",
    "    x: pd.DataFrame,\n",
    "    df_most_correlated_cols: pd.DataFrame,\n",
    "    df_anova_fscores: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    for idx in df_most_correlated_cols.index:\n",
    "        column1 = df_most_correlated_cols.loc[idx, 'column1']\n",
    "        column2 = df_most_correlated_cols.loc[idx, 'column2']\n",
    "        score_column1 = df_anova_fscores.loc[\n",
    "            df_anova_fscores['features'] == column1, 'score'\n",
    "        ].ravel()\n",
    "        score_column2 = df_anova_fscores.loc[\n",
    "            df_anova_fscores['features'] == column2, 'score'\n",
    "        ].ravel()\n",
    "        if score_column1 > score_column2:\n",
    "            df_most_correlated_cols.loc[idx, 'drop'] = column2\n",
    "        else:\n",
    "            df_most_correlated_cols.loc[idx, 'drop'] = column1\n",
    "    drop_features = list(df_most_correlated_cols['drop'].unique())\n",
    "    print(\"removed by correlation: \", drop_features)\n",
    "    df_removed_columns = x.drop(columns=drop_features, axis=1)\n",
    "    return df_removed_columns\n",
    "\n",
    "\n",
    "def _remove_columns_by_fvalue(\n",
    "    df_clean1: pd.DataFrame,\n",
    "    df_anova_fscores: pd.DataFrame,\n",
    "    threshold: float\n",
    ") -> pd.DataFrame:\n",
    "    df_anova_fscores = df_anova_fscores[df_anova_fscores['score'] > threshold]\n",
    "    df_removed_columns = df_clean1[df_anova_fscores['features']]\n",
    "    return df_removed_columns\n",
    "\n",
    "\n",
    "def feature_selection_correlation_anova(\n",
    "    df_encoded_data: pd.DataFrame,\n",
    "    target: str, threshold: Dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs feature selection based on correlation and ANOVA F-value\n",
    "    criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - df_encoded_data (pd.DataFrame): The input DataFrame with encoded\n",
    "      features.\n",
    "    - target (str): The name of the target variable.\n",
    "    - threshold (Dict): A dictionary containing threshold values for\n",
    "      feature selection.\n",
    "        - 'corr_threshold' (float): Threshold for correlation coefficient.\n",
    "        - 'fvalue_threshold' (float): Threshold for ANOVA F-value.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with selected features based on\n",
    "      correlation and ANOVA F-value.\n",
    "    \"\"\"\n",
    "    x = df_encoded_data.drop(columns=[target])\n",
    "    y = df_encoded_data[target]\n",
    "\n",
    "    df_anova_fscores = _get_anova_fvalue(x, y)\n",
    "    df_most_correlated_cols = _get_correlations(\n",
    "        x, threshold['corr_threshold']\n",
    "    )\n",
    "    df_clean1 = _remove_columns_by_correlation(\n",
    "        x, df_most_correlated_cols, df_anova_fscores\n",
    "    )\n",
    "    df_model_input = _remove_columns_by_fvalue(\n",
    "        df_clean1, df_anova_fscores, threshold['fvalue_threshold']\n",
    "    )\n",
    "    df_model_input[target] = y\n",
    "\n",
    "    return df_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score, precision_score,\n",
    "    recall_score, make_scorer, confusion_matrix\n",
    ")\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def split_data(\n",
    "    df: pd.DataFrame,\n",
    "    target_variable: str,\n",
    "    model_options_lg: Dict\n",
    ") -> Tuple:\n",
    "    y = df[target_variable]\n",
    "    x = df.drop(columns=[target_variable])\n",
    "\n",
    "    strat_shuf_split = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=model_options_lg['test_size'],\n",
    "        random_state=model_options_lg['random_state']\n",
    "    )\n",
    "\n",
    "    train_idx, test_idx = next(strat_shuf_split.split(x, y))\n",
    "    x_train = df.loc[train_idx, x.columns]\n",
    "    y_train = df.loc[train_idx, target_variable]\n",
    "    x_test = df.loc[test_idx, x.columns]\n",
    "    y_test = df.loc[test_idx, target_variable]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    x_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    model_options_lg: Dict\n",
    ") -> Any:\n",
    "    skf = StratifiedKFold(shuffle=True,\n",
    "                          random_state=model_options_lg['random_state'],\n",
    "                          n_splits=model_options_lg['n_splits'])\n",
    "\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'f1': make_scorer(f1_score, average='macro')\n",
    "    }\n",
    "\n",
    "    if model_options_lg['model'] == \"LogisticRegression\":\n",
    "        lreg = LogisticRegression()\n",
    "\n",
    "        estimator = Pipeline([\n",
    "            # (\"polynomial_features\", PolynomialFeatures()),\n",
    "            (\"scaler\", ss),\n",
    "            (\"logistic_regression\", lreg)])\n",
    "\n",
    "        params = {\n",
    "            # 'polynomial_features__degree': [1, 2, 3],\n",
    "            'logistic_regression__penalty': ['l1', 'l2'],\n",
    "            'logistic_regression__C': [4, 6, 10],\n",
    "            'logistic_regression__solver': ['liblinear']\n",
    "        }\n",
    "\n",
    "    elif model_options_lg['model'] == \"SVC\":\n",
    "        svc = SVC()\n",
    "\n",
    "        estimator = Pipeline([\n",
    "            # (\"polynomial_features\", PolynomialFeatures()),\n",
    "            (\"scaler\", ss),\n",
    "            (\"svc_classifier\", svc)])\n",
    "\n",
    "        params = {\n",
    "            # 'polynomial_features__degree': [1, 2,3],\n",
    "            'svc_classifier__C': [2, 4, 6],\n",
    "            'svc_classifier__kernel': ['rbf', 'sigmoid']\n",
    "        }\n",
    "    elif model_options_lg['model'] == \"RandomForest\":\n",
    "        rf = RandomForestClassifier()\n",
    "\n",
    "        estimator = Pipeline([\n",
    "            # (\"polynomial_features\", PolynomialFeatures()),\n",
    "            (\"scaler\", ss),\n",
    "            (\"RF_classifier\", rf)])\n",
    "\n",
    "        params = {\n",
    "            # 'polynomial_features__degree': [1, 2,3],\n",
    "            'RF_classifier__n_estimators': [350, 400, 450],\n",
    "            'RF_classifier__max_depth': [None, 20],\n",
    "            'RF_classifier__warm_start': [True]\n",
    "        }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator, params, scoring=scoring, refit='f1', cv=skf, n_jobs=-1\n",
    "    )\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: Any,\n",
    "    x_test: pd.DataFrame,\n",
    "    y_test: pd.Series\n",
    "):\n",
    "    score, params = model.best_score_, model.best_params_\n",
    "    print(\"Best score: \", score)\n",
    "    print(\"Best params: \", params)\n",
    "    predictions = model.predict(x_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(model.cv_results_['mean_test_f1'])\n",
    "    cr = classification_report(y_test, predictions, output_dict=True)\n",
    "    df_cr = pd.DataFrame(cr).iloc[:-1, :].T\n",
    "    sns.heatmap(df_cr, annot=True)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yaml_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "yaml_file_path = 'C:/Users/luisg/Documents/projects/data_science_bank_churn/conf/base/parameters/data_processing.yml'\n",
    "yaml_data = load_yaml_file(yaml_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_variable': 'Attrition_Flag',\n",
       " 'delete_columns': {'threshold': 0.05, 'selected_columns': ['CLIENTNUM']},\n",
       " 'reduce_options_columns': {'threshold': 0.03, 'exclude': ['Attrition_Flag']},\n",
       " 'outliers_columns': ['Customer_Age',\n",
       "  'Dependent_count',\n",
       "  'Months_on_book',\n",
       "  'Total_Relationship_Count',\n",
       "  'Months_Inactive_12_mon',\n",
       "  'Contacts_Count_12_mon',\n",
       "  'Credit_Limit',\n",
       "  'Total_Revolving_Bal',\n",
       "  'Avg_Open_To_Buy',\n",
       "  'Total_Amt_Chng_Q4_Q1',\n",
       "  'Total_Trans_Amt',\n",
       "  'Total_Trans_Ct',\n",
       "  'Total_Ct_Chng_Q4_Q1',\n",
       "  'Avg_Utilization_Ratio'],\n",
       " 'skewed_columns': {'method': 'log', 'exclude_columns': []},\n",
       " 'feature_selection': {'corr_threshold': 0.9, 'fvalue_threshold': 1}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yaml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before removing:  (10127, 20)\n",
      "Outliers deleted:  [('Customer_Age', 1), ('Months_Inactive_12_mon', 124), ('Contacts_Count_12_mon', 620), ('Total_Amt_Chng_Q4_Q1', 159), ('Total_Trans_Amt', 308), ('Total_Trans_Ct', 7), ('Total_Ct_Chng_Q4_Q1', 92)]\n",
      "Shape after removing:  (8816, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>1247</td>\n",
       "      <td>2763.0</td>\n",
       "      <td>1.376</td>\n",
       "      <td>1088</td>\n",
       "      <td>24</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$120K +</td>\n",
       "      <td>Blue</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6748.0</td>\n",
       "      <td>1467</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1201</td>\n",
       "      <td>42</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>680</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1570</td>\n",
       "      <td>29</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14470.0</td>\n",
       "      <td>1157</td>\n",
       "      <td>13313.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1207</td>\n",
       "      <td>21</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>1.047</td>\n",
       "      <td>692</td>\n",
       "      <td>16</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0          0            44      M                2        Graduate   \n",
       "1          0            42      M                5      Uneducated   \n",
       "2          0            57      F                2        Graduate   \n",
       "3          0            45      F                2        Graduate   \n",
       "4          1            62      F                0        Graduate   \n",
       "\n",
       "  Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0        Married     $40K - $60K          Blue              36   \n",
       "1        Unknown         $120K +          Blue              31   \n",
       "2        Married  Less than $40K          Blue              48   \n",
       "3        Married         Unknown          Blue              37   \n",
       "4        Married  Less than $40K          Blue              49   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                         3                       1                      2   \n",
       "1                         5                       3                      2   \n",
       "2                         5                       2                      2   \n",
       "3                         6                       1                      2   \n",
       "4                         2                       3                      3   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0        4010.0                 1247           2763.0                 1.376   \n",
       "1        6748.0                 1467           5281.0                 0.831   \n",
       "2        2436.0                  680           1756.0                 1.190   \n",
       "3       14470.0                 1157          13313.0                 0.966   \n",
       "4        1438.3                    0           1438.3                 1.047   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1088              24                0.846                  0.311  \n",
       "1             1201              42                0.680                  0.217  \n",
       "2             1570              29                0.611                  0.279  \n",
       "3             1207              21                0.909                  0.080  \n",
       "4              692              16                0.600                  0.000  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(\n",
    "    'C:/Users/luisg/Documents/projects/data_science_bank_churn/data/01_raw/BankChurners.csv',\n",
    "    usecols=['Attrition_Flag', 'Customer_Age', 'Gender',\n",
    "       'Dependent_count', 'Education_Level', 'Marital_Status',\n",
    "       'Income_Category', 'Card_Category', 'Months_on_book',\n",
    "       'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
    "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
    "       'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt',\n",
    "       'Total_Trans_Ct', 'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio']\n",
    ")\n",
    "\n",
    "\n",
    "def transform_target(df, target_variable):\n",
    "    df[target_variable] = df[target_variable].apply(\n",
    "        lambda x: 0 if x == \"Existing Customer\" else 1\n",
    "    )\n",
    "    df.rename(columns={target_variable: \"Attrition\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_outliers(\n",
    "    df: pd.DataFrame,\n",
    "    outliers_columns: Dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handles outliers in specified columns of a DataFrame based on statistical\n",
    "    tests and boundary criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - outliers_columns (Dict): A dictionary containing information about\n",
    "      columns with outliers.\n",
    "        - Keys: Column names with outliers.\n",
    "        - Values: Not used. Can be an empty dictionary or any placeholder.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    print(\"Shape before removing: \", df.shape)\n",
    "    transformed_columns = []\n",
    "\n",
    "    for col in outliers_columns:\n",
    "        p_value = normaltest(df[col].values)[1]\n",
    "        if p_value < 0.05:\n",
    "            uppper_boundary = df[col].mean() + 3 * df[col].std()\n",
    "            lower_boundary = df[col].mean() - 3 * df[col].std()\n",
    "        else:\n",
    "            IQR = df[col].quantile(0.75) - df[col].quantile(0.25)\n",
    "            lower_boundary = df[col].quantile(0.25) - (IQR * 1.5)\n",
    "            uppper_boundary = df[col].quantile(0.75) + (IQR * 1.5)\n",
    "        outliers = df[\n",
    "            (df[col] < lower_boundary) | (df[col] > uppper_boundary)\n",
    "        ].index.tolist()\n",
    "\n",
    "        if len(outliers) > 0:\n",
    "            df.drop(outliers, axis=0, inplace=True)\n",
    "            transformed_columns.append((col, len(outliers)))\n",
    "\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    if len(transformed_columns) > 0:\n",
    "        print(\"Outliers deleted: \", transformed_columns)\n",
    "        print(\"Shape after removing: \", df.shape)\n",
    "    else:\n",
    "        print(\"There are not outliers\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def reduce_categorical_column_options(\n",
    "        df: pd.DataFrame,\n",
    "        reduce_columns: Dict\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reduces the number of options in categorical columns of a DataFrame based\n",
    "    on specified criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - reduce_columns (Dict): A dictionary containing information about columns\n",
    "      to be reduced.\n",
    "        - 'threshold' (float): Threshold for reducing categories. Categories\n",
    "          with a frequency below this threshold will be replaced with\n",
    "          'others'.\n",
    "        - 'colums' (List): columns names\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with reduced categorical options.\n",
    "    \"\"\"\n",
    "    df_data_red = df.copy()\n",
    "    combined_col_names = []\n",
    "    for col in reduce_columns['columns']:\n",
    "        val_counts = df[col].value_counts()\n",
    "        replace_cats = list(\n",
    "            val_counts[\n",
    "                (val_counts / val_counts.sum()) < reduce_columns['threshold']\n",
    "            ].index\n",
    "        )\n",
    "        if len(replace_cats) > 0:\n",
    "            df_data_red[col] = df_data_red.replace(replace_cats, 'others')[col]\n",
    "            combined_col_names.append(col)\n",
    "\n",
    "    if len(combined_col_names) > 0:\n",
    "        print(\"Reduced columns: \", combined_col_names)\n",
    "    else:\n",
    "        print(\"Not reduced columns\")\n",
    "\n",
    "    return df_data_red\n",
    "\n",
    "\n",
    "def get_preprocessor(\n",
    "    df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encodes categorical columns in a DataFrame using various encoding\n",
    "    techniques.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input DataFrame.\n",
    "    - target_variable (str): The name of the target variable for binary\n",
    "      encoding.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with encoded categorical columns.\n",
    "    \"\"\"\n",
    "    target_variable = 'Attrition'\n",
    "    # y = df[target_variable]\n",
    "    x = df.drop(columns=[target_variable])\n",
    "\n",
    "\n",
    "    education_order = ['Unknown', 'Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate']\n",
    "    income_order = [\"Unknown\", \"Less than $40K\", \"$40K - $60K\", \"$60K - $80K\", \"$80K - $120K\", \"$120K +\"]\n",
    "\n",
    "\n",
    "    # Create a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('Custom_education', OrdinalEncoder(categories=[education_order]), ['Education_Level']),\n",
    "            ('Custom_income', OrdinalEncoder(categories=[income_order]), ['Income_Category']),\n",
    "            ('MinMax', MinMaxScaler(), ['Customer_Age', 'Months_on_book', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Amt']),\n",
    "            ('Ordinal', OrdinalEncoder(), ['Marital_Status', 'Gender']),\n",
    "            ('onehot', OneHotEncoder(), ['Card_Category'])\n",
    "        ],\n",
    "        remainder='passthrough', # Leave the other columns unchanged\n",
    "\n",
    "    )\n",
    "\n",
    "    # Label encoder\n",
    "    preprocessor.fit(x) \n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "\n",
    "# Data preprocessing - COMPLETE DATASET (BEFORE SPLIT)\n",
    "df_data = transform_target(df_data, 'Attrition_Flag')\n",
    "\n",
    "# Data preprocessing - COMPLETE DATASET (AFTER SPLIT) only on train set\n",
    "df_data = handle_outliers(df_data, ['Customer_Age',\n",
    "  'Dependent_count',\n",
    "  'Months_on_book',\n",
    "  'Total_Relationship_Count',\n",
    "  'Months_Inactive_12_mon',\n",
    "  'Contacts_Count_12_mon',\n",
    "  'Credit_Limit',\n",
    "  'Total_Revolving_Bal',\n",
    "  'Avg_Open_To_Buy',\n",
    "  'Total_Amt_Chng_Q4_Q1',\n",
    "  'Total_Trans_Amt',\n",
    "  'Total_Trans_Ct',\n",
    "  'Total_Ct_Chng_Q4_Q1',\n",
    "  'Avg_Utilization_Ratio']\n",
    ")\n",
    "# df_data = reduce_categorical_column_options(\n",
    "#     df_data,\n",
    "#     {\n",
    "#         'columns': ['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'],\n",
    "#         'threshold': 0.03\n",
    "#     }\n",
    "# )\n",
    "\n",
    "preprocessor = get_preprocessor(df_data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4010.0</td>\n",
       "      <td>1247</td>\n",
       "      <td>2763.0</td>\n",
       "      <td>1.376</td>\n",
       "      <td>1088</td>\n",
       "      <td>24</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$120K +</td>\n",
       "      <td>Blue</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6748.0</td>\n",
       "      <td>1467</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>0.831</td>\n",
       "      <td>1201</td>\n",
       "      <td>42</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>680</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1570</td>\n",
       "      <td>29</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14470.0</td>\n",
       "      <td>1157</td>\n",
       "      <td>13313.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>1207</td>\n",
       "      <td>21</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>1.047</td>\n",
       "      <td>692</td>\n",
       "      <td>16</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0          0            44      M                2        Graduate   \n",
       "1          0            42      M                5      Uneducated   \n",
       "2          0            57      F                2        Graduate   \n",
       "3          0            45      F                2        Graduate   \n",
       "4          1            62      F                0        Graduate   \n",
       "\n",
       "  Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0        Married     $40K - $60K          Blue              36   \n",
       "1        Unknown         $120K +          Blue              31   \n",
       "2        Married  Less than $40K          Blue              48   \n",
       "3        Married         Unknown          Blue              37   \n",
       "4        Married  Less than $40K          Blue              49   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                         3                       1                      2   \n",
       "1                         5                       3                      2   \n",
       "2                         5                       2                      2   \n",
       "3                         6                       1                      2   \n",
       "4                         2                       3                      3   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0        4010.0                 1247           2763.0                 1.376   \n",
       "1        6748.0                 1467           5281.0                 0.831   \n",
       "2        2436.0                  680           1756.0                 1.190   \n",
       "3       14470.0                 1157          13313.0                 0.966   \n",
       "4        1438.3                    0           1438.3                 1.047   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1088              24                0.846                  0.311  \n",
       "1             1201              42                0.680                  0.217  \n",
       "2             1570              29                0.611                  0.279  \n",
       "3             1207              21                0.909                  0.080  \n",
       "4              692              16                0.600                  0.000  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.Card_Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "      <td>8816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.167083</td>\n",
       "      <td>46.316357</td>\n",
       "      <td>2.351293</td>\n",
       "      <td>35.898707</td>\n",
       "      <td>3.830649</td>\n",
       "      <td>2.299342</td>\n",
       "      <td>2.499433</td>\n",
       "      <td>8438.061207</td>\n",
       "      <td>1149.609347</td>\n",
       "      <td>7288.451860</td>\n",
       "      <td>0.741933</td>\n",
       "      <td>4126.729923</td>\n",
       "      <td>64.345168</td>\n",
       "      <td>0.694257</td>\n",
       "      <td>0.278638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.373071</td>\n",
       "      <td>7.948977</td>\n",
       "      <td>1.298240</td>\n",
       "      <td>7.914192</td>\n",
       "      <td>1.557597</td>\n",
       "      <td>0.931520</td>\n",
       "      <td>0.929628</td>\n",
       "      <td>9019.391051</td>\n",
       "      <td>815.940024</td>\n",
       "      <td>9025.217553</td>\n",
       "      <td>0.180310</td>\n",
       "      <td>2776.243793</td>\n",
       "      <td>21.796597</td>\n",
       "      <td>0.195916</td>\n",
       "      <td>0.278417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1438.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2494.750000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>1251.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2199.750000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4358.500000</td>\n",
       "      <td>1259.000000</td>\n",
       "      <td>3304.500000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>3915.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.694000</td>\n",
       "      <td>0.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10678.250000</td>\n",
       "      <td>1769.000000</td>\n",
       "      <td>9528.500000</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>4691.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>0.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34516.000000</td>\n",
       "      <td>2517.000000</td>\n",
       "      <td>34516.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>14807.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attrition  Customer_Age  Dependent_count  Months_on_book  \\\n",
       "count  8816.000000   8816.000000      8816.000000     8816.000000   \n",
       "mean      0.167083     46.316357         2.351293       35.898707   \n",
       "std       0.373071      7.948977         1.298240        7.914192   \n",
       "min       0.000000     26.000000         0.000000       13.000000   \n",
       "25%       0.000000     41.000000         1.000000       32.000000   \n",
       "50%       0.000000     46.000000         2.000000       36.000000   \n",
       "75%       0.000000     52.000000         3.000000       40.000000   \n",
       "max       1.000000     70.000000         5.000000       56.000000   \n",
       "\n",
       "       Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "count               8816.000000             8816.000000   \n",
       "mean                   3.830649                2.299342   \n",
       "std                    1.557597                0.931520   \n",
       "min                    1.000000                0.000000   \n",
       "25%                    3.000000                2.000000   \n",
       "50%                    4.000000                2.000000   \n",
       "75%                    5.000000                3.000000   \n",
       "max                    6.000000                5.000000   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
       "count            8816.000000   8816.000000          8816.000000   \n",
       "mean                2.499433   8438.061207          1149.609347   \n",
       "std                 0.929628   9019.391051           815.940024   \n",
       "min                 1.000000   1438.300000             0.000000   \n",
       "25%                 2.000000   2494.750000           168.000000   \n",
       "50%                 3.000000   4358.500000          1259.000000   \n",
       "75%                 3.000000  10678.250000          1769.000000   \n",
       "max                 4.000000  34516.000000          2517.000000   \n",
       "\n",
       "       Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "count      8816.000000           8816.000000      8816.000000     8816.000000   \n",
       "mean       7288.451860              0.741933      4126.729923       64.345168   \n",
       "std        9025.217553              0.180310      2776.243793       21.796597   \n",
       "min           3.000000              0.120000       510.000000       10.000000   \n",
       "25%        1251.500000              0.625000      2199.750000       46.000000   \n",
       "50%        3304.500000              0.730000      3915.000000       67.000000   \n",
       "75%        9528.500000              0.848000      4691.250000       80.000000   \n",
       "max       34516.000000              1.400000     14807.000000      130.000000   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "count          8816.000000            8816.000000  \n",
       "mean              0.694257               0.278638  \n",
       "std               0.195916               0.278417  \n",
       "min               0.038000               0.000000  \n",
       "25%               0.574000               0.010500  \n",
       "50%               0.694000               0.179500  \n",
       "75%               0.811000               0.513000  \n",
       "max               1.370000               0.999000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df_data.columns:\n",
    "#     print(column, df_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, FunctionTransformer, OrdinalEncoder\n",
    "\n",
    "\n",
    "# df = df_data.copy()\n",
    "# target_variable = 'Attrition'\n",
    "# y = df[target_variable]\n",
    "# x = df.drop(columns=[target_variable])\n",
    "\n",
    "\n",
    "# education_order = ['Unknown', 'Uneducated', 'High School', 'College', 'Graduate', 'Post-Graduate', 'Doctorate']\n",
    "# income_order = [\"Unknown\", \"Less than $40K\", \"$40K - $60K\", \"$60K - $80K\", \"$80K - $120K\", \"$120K +\"]\n",
    "\n",
    "\n",
    "# # Create a ColumnTransformer\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('Custom_education', OrdinalEncoder(categories=[education_order]), ['Education_Level']),\n",
    "#         ('Custom_income', OrdinalEncoder(categories=[income_order]), ['Income_Category']),\n",
    "#         ('MinMax', MinMaxScaler(), ['Customer_Age', 'Months_on_book', 'Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy', 'Total_Trans_Amt']),\n",
    "#         ('Ordinal', OrdinalEncoder(), ['Marital_Status', 'Gender']),\n",
    "#         ('onehot', OneHotEncoder(), ['Card_Category'])\n",
    "#     ],\n",
    "#     remainder='passthrough', # Leave the other columns unchanged\n",
    "\n",
    "# )\n",
    "\n",
    "# # Label encoder\n",
    "# preprocessor.fit(x) \n",
    "# preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_yaml_file(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         data = yaml.safe_load(file)\n",
    "#     return data\n",
    "\n",
    "# # Example usage\n",
    "# yaml_file_path = 'C:/Users/luisg/Documents/projects/data_science_bank_churn/conf/base/parameters/data_science.yml'\n",
    "# yaml_training_data = load_yaml_file(yaml_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def split_dataset(df, preprocessor):\n",
    "    target_variable = 'Attrition'\n",
    "    y = df[target_variable]\n",
    "    x = df.drop(columns=[target_variable])\n",
    "    strat_shuf_split = StratifiedShuffleSplit(\n",
    "        n_splits=1, test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_idx, test_idx = next(strat_shuf_split.split(x, y))\n",
    "    x_train = x.iloc[train_idx, :]\n",
    "    y_train = y[train_idx]\n",
    "    x_test = x.loc[test_idx, :]\n",
    "    y_test = y[test_idx]\n",
    "    x_train = preprocessor.fit_transform(x_train)\n",
    "    x_test = preprocessor.transform(x_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, models, param):\n",
    "    report = {}\n",
    "    scoring = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score, average='macro'),\n",
    "        'recall': make_scorer(recall_score, average='macro'),\n",
    "        'f1': make_scorer(f1_score, average='macro')\n",
    "    }\n",
    "    skf = StratifiedKFold(shuffle=True, random_state=42, n_splits=3)\n",
    "\n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        para=param[list(models.keys())[i]]\n",
    "\n",
    "        gs = GridSearchCV(model, para, cv=skf, scoring=scoring, refit='f1')\n",
    "        gs.fit(X_train,y_train)\n",
    "\n",
    "        model.set_params(**gs.best_params_)\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        # y_train_pred = model.predict(X_train)\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "        report[list(models.keys())[i]] = {\n",
    "            'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'precision': precision_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred),\n",
    "            'f1': f1_score(y_test, y_test_pred)\n",
    "        }\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(),\n",
    "        \"KNeighbors Classifier\": KNeighborsClassifier(),\n",
    "        \"Support Vector Machine\": SVC(),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"GradientBoosting Classifier\": GradientBoostingClassifier(),\n",
    "        \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "        \"XGB Classifier\": XGBClassifier()\n",
    "    }\n",
    "    params={\n",
    "        \"Logistic Regression\": {\n",
    "            'penalty':['l2', 'l1'],\n",
    "            'solver':['liblinear']\n",
    "        },\n",
    "        \"KNeighbors Classifier\":{\n",
    "            'n_neighbors':[5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        },\n",
    "        \"Support Vector Machine\":{\n",
    "            'kernel':['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        },\n",
    "        \"Random Forest\":{\n",
    "            'n_estimators': [100, 200]\n",
    "        },\n",
    "        \"GradientBoosting Classifier\":{\n",
    "            'n_estimators': [100, 200]\n",
    "        },\n",
    "        \"AdaBoost Classifier\":{\n",
    "            'n_estimators': [100, 200]\n",
    "        },\n",
    "        \"XGB Classifier\":{\n",
    "            'n_estimators': [100, 200]\n",
    "        }\n",
    "        \n",
    "    }\n",
    "\n",
    "    model_report = evaluate_models(X_train=x_train, y_train=y_train, X_test=x_test, y_test=y_test,\n",
    "                                        models=models, param=params)\n",
    "    \n",
    "    # ## To get best model score from dict\n",
    "    best_model_name, _ = sorted([(model, score) for model, scores in model_report.items() for metric, score in scores.items() if metric == 'f1'], reverse=True, key= lambda x: x[1])[0]\n",
    "\n",
    "    best_model = models[best_model_name]\n",
    "    # return model_report, best_model_name, best_model\n",
    "    return best_model\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_dataset(df_data, preprocessor)\n",
    "# report, best_model_name, best_model = train_model(x_train, y_train, x_test, y_test)\n",
    "# best_model = train_model(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'accuracy': 0.8990929705215419,\n",
       "  'precision': 0.7532467532467533,\n",
       "  'recall': 0.5898305084745763,\n",
       "  'f1': 0.6615969581749049},\n",
       " 'KNeighbors Classifier': {'accuracy': 0.8696145124716553,\n",
       "  'precision': 0.6470588235294118,\n",
       "  'recall': 0.4847457627118644,\n",
       "  'f1': 0.5542635658914729},\n",
       " 'Support Vector Machine': {'accuracy': 0.9013605442176871,\n",
       "  'precision': 0.784037558685446,\n",
       "  'recall': 0.5661016949152542,\n",
       "  'f1': 0.6574803149606299},\n",
       " 'Random Forest': {'accuracy': 0.9563492063492064,\n",
       "  'precision': 0.9128787878787878,\n",
       "  'recall': 0.8169491525423729,\n",
       "  'f1': 0.8622540250447227},\n",
       " 'GradientBoosting Classifier': {'accuracy': 0.9671201814058957,\n",
       "  'precision': 0.9128919860627178,\n",
       "  'recall': 0.888135593220339,\n",
       "  'f1': 0.9003436426116839},\n",
       " 'AdaBoost Classifier': {'accuracy': 0.9586167800453514,\n",
       "  'precision': 0.8775510204081632,\n",
       "  'recall': 0.8745762711864407,\n",
       "  'f1': 0.8760611205432938},\n",
       " 'XGB Classifier': {'accuracy': 0.969954648526077,\n",
       "  'precision': 0.9087837837837838,\n",
       "  'recall': 0.911864406779661,\n",
       "  'f1': 0.910321489001692}}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XGB Classifier'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.910321489001692"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, best_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7052, 22)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/luisg/Documents/projects/data_science_bank_churn/data/06_models/model_notebook.pkl')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "file_path = Path.cwd()\n",
    "model_path = file_path.parent / \"data\" / \"06_models\" / \"model_notebook.pkl\"\n",
    "preprocessor_path = file_path.parent / \"data\" / \"06_models\" / \"preprocessor.pkl\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model using pickle\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Save the preprocessor using pickle\n",
    "with open(preprocessor_path, 'wb') as file:\n",
    "    pickle.dump(preprocessor, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisg\\Documents\\projects\\data_science_bank_churn\\data\\06_models\\model_notebook.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Now you can load the model later if needed\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Now you can load the model later if needed\n",
    "with open(preprocessor_path, 'rb') as file:\n",
    "    preprocessor = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>2145</td>\n",
       "      <td>6736.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>2027</td>\n",
       "      <td>49</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>54</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Silver</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12547.0</td>\n",
       "      <td>1378</td>\n",
       "      <td>11169.0</td>\n",
       "      <td>1.120</td>\n",
       "      <td>3360</td>\n",
       "      <td>56</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0.472</td>\n",
       "      <td>2005</td>\n",
       "      <td>47</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4123.0</td>\n",
       "      <td>1760</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>0.869</td>\n",
       "      <td>2447</td>\n",
       "      <td>40</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9478.0</td>\n",
       "      <td>820</td>\n",
       "      <td>8658.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1327</td>\n",
       "      <td>41</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6904.0</td>\n",
       "      <td>1148</td>\n",
       "      <td>5756.0</td>\n",
       "      <td>0.649</td>\n",
       "      <td>3485</td>\n",
       "      <td>84</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7966.0</td>\n",
       "      <td>1423</td>\n",
       "      <td>6543.0</td>\n",
       "      <td>0.987</td>\n",
       "      <td>3780</td>\n",
       "      <td>75</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7599.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>6499.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>4401</td>\n",
       "      <td>71</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3685.0</td>\n",
       "      <td>1396</td>\n",
       "      <td>2289.0</td>\n",
       "      <td>0.974</td>\n",
       "      <td>3016</td>\n",
       "      <td>85</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>1904</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>0.891</td>\n",
       "      <td>5025</td>\n",
       "      <td>84</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer_Age Gender  Dependent_count Education_Level Marital_Status  \\\n",
       "999             56      F                4     High School         Single   \n",
       "1697            54      F                0        Graduate       Divorced   \n",
       "653             26      M                0        Graduate         Single   \n",
       "3863            51      M                2     High School        Married   \n",
       "271             46      F                4        Graduate       Divorced   \n",
       "...            ...    ...              ...             ...            ...   \n",
       "4616            39      F                1      Uneducated         Single   \n",
       "2784            46      F                2     High School        Unknown   \n",
       "3136            43      M                5        Graduate        Unknown   \n",
       "1428            37      F                3        Graduate         Single   \n",
       "5635            42      F                1        Graduate         Single   \n",
       "\n",
       "     Income_Category Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "999   Less than $40K          Blue              36                         3   \n",
       "1697  Less than $40K        Silver              36                         4   \n",
       "653          Unknown          Blue              19                         4   \n",
       "3863     $60K - $80K          Blue              46                         5   \n",
       "271   Less than $40K          Blue              36                         5   \n",
       "...              ...           ...             ...                       ...   \n",
       "4616  Less than $40K          Blue              34                         3   \n",
       "2784         Unknown          Blue              32                         4   \n",
       "3136     $40K - $60K          Blue              38                         3   \n",
       "1428  Less than $40K          Blue              36                         5   \n",
       "5635  Less than $40K          Blue              36                         4   \n",
       "\n",
       "      Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "999                        1                      3        8881.0   \n",
       "1697                       3                      1       12547.0   \n",
       "653                        1                      2        1438.3   \n",
       "3863                       3                      2        4123.0   \n",
       "271                        3                      1        9478.0   \n",
       "...                      ...                    ...           ...   \n",
       "4616                       1                      4        6904.0   \n",
       "2784                       1                      3        7966.0   \n",
       "3136                       3                      2        7599.0   \n",
       "1428                       2                      4        3685.0   \n",
       "5635                       3                      1        3595.0   \n",
       "\n",
       "      Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "999                  2145           6736.0                 0.705   \n",
       "1697                 1378          11169.0                 1.120   \n",
       "653                     0           1438.3                 0.472   \n",
       "3863                 1760           2363.0                 0.869   \n",
       "271                   820           8658.0                 0.640   \n",
       "...                   ...              ...                   ...   \n",
       "4616                 1148           5756.0                 0.649   \n",
       "2784                 1423           6543.0                 0.987   \n",
       "3136                 1100           6499.0                 0.365   \n",
       "1428                 1396           2289.0                 0.974   \n",
       "5635                 1904           1691.0                 0.891   \n",
       "\n",
       "      Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  \\\n",
       "999              2027              49                0.815   \n",
       "1697             3360              56                0.750   \n",
       "653              2005              47                0.469   \n",
       "3863             2447              40                0.429   \n",
       "271              1327              41                0.864   \n",
       "...               ...             ...                  ...   \n",
       "4616             3485              84                0.615   \n",
       "2784             3780              75                0.923   \n",
       "3136             4401              71                0.651   \n",
       "1428             3016              85                0.809   \n",
       "5635             5025              84                0.647   \n",
       "\n",
       "      Avg_Utilization_Ratio  \n",
       "999                   0.242  \n",
       "1697                  0.110  \n",
       "653                   0.000  \n",
       "3863                  0.427  \n",
       "271                   0.087  \n",
       "...                     ...  \n",
       "4616                  0.166  \n",
       "2784                  0.179  \n",
       "3136                  0.145  \n",
       "1428                  0.379  \n",
       "5635                  0.530  \n",
       "\n",
       "[1764 rows x 19 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999     0\n",
       "1697    0\n",
       "653     0\n",
       "3863    1\n",
       "271     0\n",
       "       ..\n",
       "4616    0\n",
       "2784    0\n",
       "3136    0\n",
       "1428    0\n",
       "5635    0\n",
       "Name: Attrition, Length: 1764, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8979591836734694"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7322    1\n",
       "5747    0\n",
       "6555    0\n",
       "7892    1\n",
       "2816    0\n",
       "       ..\n",
       "4074    0\n",
       "7739    0\n",
       "668     0\n",
       "1430    0\n",
       "55      0\n",
       "Name: Attrition, Length: 7052, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6544930321960596"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, loaded_model.predict(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1469\n",
      "           1       0.75      0.59      0.66       295\n",
      "\n",
      "    accuracy                           0.90      1764\n",
      "   macro avg       0.83      0.77      0.80      1764\n",
      "weighted avg       0.89      0.90      0.89      1764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1411,   58],\n",
       "       [ 122,  173]], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Avg_Open_To_Buy</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>11914.0</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLIENTNUM  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0  768805383            45      M                3     High School   \n",
       "\n",
       "  Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0        Married     $60K - $80K          Blue              39   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                         5                       1                      3   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Avg_Open_To_Buy  Total_Amt_Chng_Q4_Q1  \\\n",
       "0       12691.0                  777          11914.0                 1.335   \n",
       "\n",
       "   Total_Trans_Amt  Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0             1144              42                1.625                  0.061  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_prueba = pd.read_csv('C:/Users/luisg/Documents/projects/data_science_bank_churn/data/01_raw/BankChurners.csv')\n",
    "df_prueba = df_prueba.head(1)\n",
    "df_prueba.drop(columns=['Attrition_Flag'], inplace=True)\n",
    "# df_prueba.rename(columns={\"Attrition_Flag\": \"Attrition\"}, inplace=True)\n",
    "df_prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_prueba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-715a1d0e983a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_prueba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_prueba' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(df_prueba.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Customer_Age              1 non-null      int64  \n",
      " 1   Gender                    1 non-null      object \n",
      " 2   Dependent_count           1 non-null      int64  \n",
      " 3   Education_Level           1 non-null      object \n",
      " 4   Marital_Status            1 non-null      object \n",
      " 5   Income_Category           1 non-null      object \n",
      " 6   Card_Category             1 non-null      object \n",
      " 7   Months_on_book            1 non-null      int64  \n",
      " 8   Total_Relationship_Count  1 non-null      int64  \n",
      " 9   Months_Inactive_12_mon    1 non-null      int64  \n",
      " 10  Contacts_Count_12_mon     1 non-null      int64  \n",
      " 11  Credit_Limit              1 non-null      float64\n",
      " 12  Total_Revolving_Bal       1 non-null      int64  \n",
      " 13  Avg_Open_To_Buy           1 non-null      float64\n",
      " 14  Total_Amt_Chng_Q4_Q1      1 non-null      float64\n",
      " 15  Total_Trans_Amt           1 non-null      int64  \n",
      " 16  Total_Trans_Ct            1 non-null      int64  \n",
      " 17  Total_Ct_Chng_Q4_Q1       1 non-null      float64\n",
      " 18  Avg_Utilization_Ratio     1 non-null      float64\n",
      "dtypes: float64(5), int64(9), object(5)\n",
      "memory usage: 280.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# df_prueba = remove_unnecessary_columns(df_prueba, yaml_data['delete_columns'])\n",
    "df_prueba.drop(columns=['CLIENTNUM'], inplace = True)\n",
    "df_prueba.reset_index(inplace=True, drop=True)\n",
    "df_prueba.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_prueba.values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'No Churn'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_prueba.drop(columns=['CLIENTNUM'], inplace= True)\n",
    "# data_scaled=preprocessor.transform(df_prueba)\n",
    "\n",
    "result_dict = {0: \"No Churn\", 1: \"Churn\"}\n",
    "result = loaded_model.predict(df_prueba)\n",
    "{'result': result_dict[result[0]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('Custom_education',\n",
       "                                 FunctionTransformer(func=<function transform_education_level at 0x0000027BD60BC598>),\n",
       "                                 ['Education_Level']),\n",
       "                                ('Custom_income',\n",
       "                                 FunctionTransformer(func=<function transform_income_category at 0x0000027BD60BC0D0>),\n",
       "                                 ['Income_Category']),\n",
       "                                ('MinMax', MinMaxScaler(),\n",
       "                                 ['Customer_Age', 'Months_on_book',\n",
       "                                  'Credit_Limit', 'Total_Revolving_Bal',\n",
       "                                  'Avg_Open_To_Buy', 'Total_Trans_Amt']),\n",
       "                                ('Ordinal', OrdinalEncoder(),\n",
       "                                 ['Marital_Status', 'Gender']),\n",
       "                                ('onehot', OneHotEncoder(), ['Card_Category'])])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankchurn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
